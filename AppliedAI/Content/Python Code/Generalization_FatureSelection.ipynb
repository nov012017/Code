{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('C:\\\\Users\\\\Administrator\\\\Desktop\\\\Prudhvi\\\\Prudhvi\\\\Data Science\\\\Data')\n",
    "os.chdir('C:\\\\Users\\\\Admin\\\\Desktop\\\\Data')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "0  No phone service             DSL             No          Yes   \n",
       "1                No             DSL            Yes           No   \n",
       "2                No             DSL            Yes          Yes   \n",
       "3  No phone service             DSL            Yes           No   \n",
       "4                No     Fiber optic             No           No   \n",
       "\n",
       "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0               No          No          No              No  Month-to-month   \n",
       "1              Yes          No          No              No        One year   \n",
       "2               No          No          No              No  Month-to-month   \n",
       "3              Yes         Yes          No              No        One year   \n",
       "4               No          No          No              No  Month-to-month   \n",
       "\n",
       "  PaperlessBilling              PaymentMethod  MonthlyCharges  TotalCharges  \\\n",
       "0              Yes           Electronic check           29.85         29.85   \n",
       "1               No               Mailed check           56.95       1889.50   \n",
       "2              Yes               Mailed check           53.85        108.15   \n",
       "3               No  Bank transfer (automatic)           42.30       1840.75   \n",
       "4              Yes           Electronic check           70.70        151.65   \n",
       "\n",
       "  Churn  \n",
       "0    No  \n",
       "1    No  \n",
       "2   Yes  \n",
       "3    No  \n",
       "4   Yes  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "telco=pd.read_csv('Telco_Customer_Attr.csv')\n",
    "telco.head()\n",
    "#print(telco.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the columns if any othem contains null or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalCharges   11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(col,' ',telco[col].isnull().sum()) for col in telco.columns if telco[col].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split\n",
    "##### Important\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(telco['Churn'])\n",
    "telco=telco.drop('Churn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3522, 20), (3521, 20))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "Kfold_X=StratifiedKFold(n_splits=2,random_state=0,shuffle=False)\n",
    "Kfold_X.get_n_splits(telco,y)\n",
    "for train_index,test_index in Kfold_X.split(telco,y):\n",
    "    X_train, X_test=telco.loc[train_index],telco.loc[test_index]\n",
    "    Y_tran, Y_test=y.loc[train_index],y.loc[test_index]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(telco,y,test_size=0.30,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting the Numeric datatype columns\n",
    "Numeric_X_train=X_train.select_dtypes(include='int64')\n",
    "Categorical_X_train=X_train.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of non constant features 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0, 54],\n",
       "       [ 0,  1],\n",
       "       [ 0, 13],\n",
       "       ...,\n",
       "       [ 0, 12],\n",
       "       [ 1, 12],\n",
       "       [ 0, 26]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0)\n",
    "sel.fit(Numeric_X_train)  # fit finds the features with zero variance\n",
    "print('Total # of non constant features',sum(sel.get_support()))\n",
    "sel.transform(Numeric_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4930, 2), (4930, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using Custom Code\n",
    "constant_features = [\n",
    "    feat for feat in Numeric_X_train.columns if Numeric_X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "len(constant_features)\n",
    "Numeric_X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "Numeric_X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "Numeric_X_train.shape, Numeric_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing constant features for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4930, 20), (2113, 20))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_features = [\n",
    "    feat for feat in Categorical_X_train.columns if len(Categorical_X_train[feat].unique()) == 1\n",
    "]\n",
    "\n",
    "print(len(constant_features))\n",
    "Categorical_X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "Categorical_X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quasi Constant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_constant_feat = []\n",
    "for feature in Categorical_X_train.columns:\n",
    "\n",
    "    # find the predominant value\n",
    "    predominant = (Categorical_X_train[feature].value_counts() / np.float(\n",
    "        len(Categorical_X_train))).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # evaluate predominant feature\n",
    "    if predominant > 0.998:\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "len(quasi_constant_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4930, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Duplicate Features\n",
    "data_t=X_train.T\n",
    "data_t.head()\n",
    "data_t.duplicated().sum()\n",
    "data_t[data_t.duplicated()] ## To visulize the duplicated rows\n",
    "duplicated_features = data_t[data_t.duplicated()].index.values\n",
    "duplicated_features\n",
    "data_unique = data_t.drop_duplicates(keep='first').T\n",
    "print(data_unique.shape)\n",
    "# to find those columns in the original dataframe that were removed:\n",
    "duplicated_features = [col for col in X_train.columns if col not in data_unique.columns]\n",
    "duplicated_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicated features in the training set\n",
    "duplicated_feat = []\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    if i % 10 == 0:  # this helps me understand how the loop is going\n",
    "        print(i)\n",
    "\n",
    "    col_1 = X_train.columns[i]\n",
    "\n",
    "    for col_2 in X_train.columns[i + 1:]:\n",
    "        if X_train[col_1].equals(X_train[col_2]):\n",
    "            duplicated_feat.append(col_2)\n",
    "print(duplicated_feat)\n",
    "print(len(set(duplicated_feat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SeniorCitizen    tenure\n",
      "SeniorCitizen       1.000000  0.006708\n",
      "tenure              0.006708  1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xcac1f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcac1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr=Numeric_X_train.corr()\n",
    "print(corr)\n",
    "fig,ax=plt.subplots()\n",
    "fig.set_size_inches(3,3)\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'TotalCharges'}\n"
     ]
    }
   ],
   "source": [
    "## Brute Force Approach\n",
    "# with the following function we can select highly correlated features\n",
    "# it will remove the first feature that is correlated with anything else\n",
    "# without any other insight.\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print(len(set(corr_features)))\n",
    "print(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>tenure</td>\n",
       "      <td>0.82643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tenure</td>\n",
       "      <td>TotalCharges</td>\n",
       "      <td>0.82643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature1      feature2     corr\n",
       "0  TotalCharges        tenure  0.82643\n",
       "1        tenure  TotalCharges  0.82643"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat = X_train.corr()\n",
    "corrmat = corrmat.abs().unstack()\n",
    "# absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.8]\n",
    "corrmat = corrmat[corrmat < 1]\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()\n",
    "#print(corrmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['tenure', 'TotalCharges']\n",
      "found 1 correlated groups\n",
      "out of 20 total features\n",
      "['tenure', 'TotalCharges']\n",
      "       feature1 feature2     corr\n",
      "0  TotalCharges   tenure  0.82643\n"
     ]
    }
   ],
   "source": [
    "grouped_feature_ls = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corrmat.feature1.unique():\n",
    "    if feature not in grouped_feature_ls:\n",
    "\n",
    "        # find all features correlated to a single feature\n",
    "        correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "        print(grouped_feature_ls)\n",
    "        grouped_feature_ls = grouped_feature_ls + list(correlated_block.feature2.unique()) + [feature]\n",
    "        print(grouped_feature_ls)\n",
    "        # append the block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('found {} correlated groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features'.format(X_train.shape[1]))\n",
    "print(grouped_feature_ls)\n",
    "print(correlated_groups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information gain - mutual information\n",
    "\n",
    "Mutual information measures how much information the presence/absence of a feature contributes to making the correct prediction on Y.\n",
    "\n",
    "As extracted from [wikipedia](https://en.wikipedia.org/wiki/Mutual_information):\n",
    "\n",
    "Mutual information measures the information that X and Y share: It measures how much knowing one of these variables reduces uncertainty about the other. For example, if X and Y are independent, then knowing X does not give any information about Y and vice versa, so their mutual information is zero. At the other extreme, if X is a deterministic function of Y and Y is a deterministic function of X then all information conveyed by X is shared with Y: knowing X determines the value of Y and vice versa. As a result, in this case the mutual information is the same as the uncertainty contained in Y (or X) alone, namely the entropy of Y (or X). Moreover, this mutual information is the same as the entropy of X and as the entropy of Y. (A very special case of this is when X and Y are the same random variable.)\n",
    "\n",
    "I will demonstrate how to select features based on mutual information using sklearn on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SeniorCitizen', 'tenure'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbee4cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "\n",
    "## For Classification\n",
    "mi=mutual_info_classif(Numeric_X_train,y_train)\n",
    "mi\n",
    "mi=pd.Series(mi)\n",
    "mi.index=Numeric_X_train.columns\n",
    "mi.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n",
    "sel_ = SelectKBest(mutual_info_classif, k=2).fit(Numeric_X_train.fillna(0), y_train)\n",
    "Numeric_X_train.columns[sel_.get_support()]\n",
    "#sel_ = SelectPercentile(mutual_info_regression, percentile=0.1).fit(Numeric_X_train.fillna(0), y_train)\n",
    "#Numeric_X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not personally used mutual information in any of my projects. However, there is some value in the method. See for example:\n",
    "\n",
    "Comparison between univariate and mutual information selection in [sklean website](http://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py)\n",
    "\n",
    "In addition, mutual information has been widely covered, if anything else from a theoretical perspective, in several articles that I share in the additional reading resources section. Therefore I wanted to have it covered in the course, and I leave it up to you to explore it and see if you find any use in it.\n",
    "\n",
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Score - chi-square implementation in sklearn\n",
    "\n",
    "Compute chi-squared stats between each non-negative feature and class. \n",
    "\n",
    "- This score should be used to evaluate categorical variables in a classification task.\n",
    "\n",
    "It compares the observed distribution of the different classes of target Y among the different categories of the feature, against the expected distribution of the target classes, regardless of the feature categories. I explained this in more detail the introductory lecture of this section.\n",
    "\n",
    "I will demonstrate how to select features using Fisher score using the titanic dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   94.87613671, 10831.80754485]), array([2.02678431e-22, 0.00000000e+00]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SeniorCitizen    2.026784e-22\n",
       "tenure           0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "# calculate the chi2 p_value between each of the variables\n",
    "# and the target\n",
    "# it returns 2 arrays, one contains the F-Scores which are then \n",
    "# evaluated against the chi2 distribution to obtain the pvalue\n",
    "# the pvalues are in the second array, see below\n",
    "\n",
    "f_score = chi2(Numeric_X_train.fillna(0), y_train)\n",
    "print(f_score)\n",
    "\n",
    "pvalues = pd.Series(f_score[1])\n",
    "pvalues.index = Numeric_X_train.columns\n",
    "pvalues.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind, that contrarily to MI, where we were interested in the higher MI values, for Fisher score, the smaller the p_value, the more significant the feature is to predict the target, in this case Survival in the titanic.\n",
    "\n",
    "Then, from the above data, Sex is the most important feature, then PClass then Embarked. \n",
    "\n",
    "**Note**\n",
    "One thing to keep in mind when using Fisher score or univariate selection methods, is that in very big datasets, most of the features will show a small p_value, and therefore look like they are highly predictive. This is in fact an effect of the sample size. So care should be taken when selecting features using these procedures. An ultra tiny p_value does not highlight an ultra-important feature, it rather indicates that the dataset contains too many samples. \n",
    "\n",
    "Finally, in this demonstration, I used chi2 over 3 categorical variables only. If the dataset contained several categorical variables, we could then combine this procedure with SelectKBest or SelectPercentile, as I did in the previous lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate feature selection\n",
    "\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests (ANOVA). The methods based on F-test estimate the degree of linear dependency between two random variables. They assume a linear relationship between the feature and the target. These methods also assume that the variables follow a Gaussian distribution.\n",
    "\n",
    "These may not always be the case for the variables in your dataset, so if looking to implement these procedure, you will need to corroborate these assumptions.\n",
    "\n",
    "I will demonstrate how to select features based on univariate tests using sklearn on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle.\n",
    "\n",
    "For the sake of the demonstration, I will assume that the variables show a linear relationship with the target, and that they are normally distributed. But when or if you choose to implement these selection procedure for your features, you will have to check that this is the case, to make sure you are implementing the right method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SeniorCitizen', 'tenure'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbee47b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the univariate statistical measure between\n",
    "# each of the variables and the target\n",
    "# similarly to chi2, the output is the array of f-scores\n",
    "# and an array of pvalues, which are the ones we will compare\n",
    "\n",
    "univariate = f_classif(Numeric_X_train.fillna(0), y_train)\n",
    "univariate\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = Numeric_X_train.columns\n",
    "univariate.sort_values(ascending=False, inplace=True)\n",
    "univariate.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n",
    "sel_ = SelectKBest(f_classif, k=2).fit(Numeric_X_train.fillna(0), y_train)\n",
    "Numeric_X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the lower the p_value, the most predictive the feature is in principle. There are a few features that do not seem to have predictive power according to this tests, which are those on the left with pvalues above 0.05. Given that typically in statistics one uses a pvalue of 0.05 as a cut-off, I am inclined to believe that those features with pvalue > 0.05 are indeed not important. However, keep in mind that this test assumes a linear relationship, so it might also be the case that the feature is related to the target but not in a linear manner.\n",
    "\n",
    "Further investigation is needed if we want to know the true nature of the relationship between feature and target.\n",
    "\n",
    "Similarly to what I mentioned in the previous lecture, in big datasets it is not unusual that the pvalues of the different features are really small. This does not say as much about the relevance of the feature. Mostly it indicates that it is a big the dataset.\n",
    "\n",
    "Once again, where we put the cut-off to select features is a bit arbitrary. One way is to select the top 10, 20 features. Alternatively, the top 10th percentile. For this, you can use anova in combination with SelectKBest or SelectPercentile from sklearn. See below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate roc-auc or mse\n",
    "\n",
    "This procedure works as follows:\n",
    "\n",
    "- First, it builds one decision tree per feature, to predict the target\n",
    "- Second, it makes predictions using the decision tree and the mentioned feature\n",
    "- Third, it ranks the features according to the machine learning metric (roc-auc or mse)\n",
    "- It selects the highest ranked features\n",
    "\n",
    "I will demonstrate how to select features based on univariate roc-auc or univariate mse information on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 20 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-951327d84562>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#roc_values.append(roc_auc_score(y_train, y_scored[:, 1]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mroc_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mroc_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mroc_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# a roc auc value of 0.5 indicates random decision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   3625\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3626\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3627\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3628\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3629\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels, fastpath)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_subtyp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_all_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m   3072\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[0;32m   3073\u001b[0m                              \u001b[1;34m'new values have %d elements'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3074\u001b[1;33m                              (old_len, new_len))\n\u001b[0m\u001b[0;32m   3075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 20 elements"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "roc_values = []\n",
    "for feature in Numeric_X_train.columns:\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(Numeric_X_train[feature].fillna(0).to_frame(), y_train)\n",
    "    y_scored = clf.predict_proba(Numeric_X_train[feature].fillna(0).to_frame())\n",
    "    #roc_values.append(roc_auc_score(y_train, y_scored[:, 1]))\n",
    "roc_values = pd.Series(roc_values)\n",
    "roc_values.index = X_train.columns\n",
    "roc_values.sort_values(ascending=False)\n",
    "# a roc auc value of 0.5 indicates random decision\n",
    "# let's check how many features show a roc-auc value\n",
    "# higher than random\n",
    "len(roc_values[roc_values > 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "98 of 112  features show a predictive performance higher than 0.5. This means that we could remove 14 features from this dataset using this method.\n",
    "\n",
    "You can of course tune the parameters of the Decision Tree and get better predictions. I leave this to you. But remember that the key here is not to make ultra predictive Decision Trees, rather to use them to screen quickly for important features. So I would recommend you don't spend too much time tuning. Doing cross validation with sklearn should be very straight forward  to get a more accurate measure of the roc-auc per feature.\n",
    "\n",
    "Once again, where we put the cut-off to select features is a bit arbitrary, other than > 0.5. It will be up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '4795-UXVCJ'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-cb197201a4d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0my_scored\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmse_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_scored\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '4795-UXVCJ'"
     ]
    }
   ],
   "source": [
    "# loop to build a tree, make predictions and get the mse\n",
    "# for each feature of the train set\n",
    "mse_values = []\n",
    "for feature in X_train.columns:\n",
    "    clf = DecisionTreeRegressor()\n",
    "    clf.fit(X_train[feature].fillna(0).to_frame(), y_train)\n",
    "    y_scored = clf.predict(X_test[feature].fillna(0).to_frame())\n",
    "    mse_values.append(mean_squared_error(y_test, y_scored))\n",
    "# let's add the variable names and order it for clearer visualisation\n",
    "mse_values = pd.Series(mse_values)\n",
    "mse_values.index = X_train.columns\n",
    "mse_values.sort_values(ascending=False)\n",
    "mse_values.sort_values(ascending=False).plot.bar(figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that for regression, the smaller the mse, the better the model performance is. So in this case, we need to select from the right to the left.\n",
    "\n",
    "For the mse, where to put the cut-off is arbitrary as well. It depends on how many features you would like to end up with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step forward feature selection\n",
    "\n",
    "Sequential feature selection algorithms are a family of greedy search algorithms that are used to reduce an initial d-dimensional feature space to a k-dimensional feature subspace where k < d.\n",
    "\n",
    "Step forward feature selection starts by evaluating all features individually and selects the one that generates the best performing algorithm, according to a pre-set evaluation criteria. In the second step, it evaluates all possible combinations of the selected feature and a second feature, and selects the pair that produce the best performing algorithm based on the same pre-set criteria.\n",
    "\n",
    "The pre-set criteria can be the roc_auc for classification and the r squared for regression for example. \n",
    "\n",
    "This selection procedure is called greedy, because it evaluates all possible single, double, triple and so on feature combinations. Therefore, it is quite computationally expensive, and sometimes, if feature space is big, even unfeasible.\n",
    "\n",
    "There is a special package for python that implements this type of feature selection: mlxtend.\n",
    "\n",
    "In the mlxtend implementation of the step forward feature selection, the stopping criteria is an arbitrarily set number of features. So the search will finish when we reach the desired number of selected features. \n",
    "\n",
    "This is somewhat arbitrary because we may be selecting a subopimal number of features, or likewise, a high number of features. \n",
    "\n",
    "Here I will use the Step Forward feature selection algorithm from mlxtend in a classification (Paribas) and regression (House Price) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the missing values using the Stratified mean value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_No_TotalCharges=telco.groupby('gender')['TotalCharges'].mean()['Female']\n",
    "Mean_Yes_TotalCharges=telco.groupby('gender')['TotalCharges'].mean()['Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.loc[(telco['TotalCharges'].isnull()) & (telco['gender']=='Female'),['TotalCharges']]=Mean_No_TotalCharges\n",
    "telco.loc[(telco['TotalCharges'].isnull()) & (telco['gender']=='Male'),['TotalCharges']]=Mean_Yes_TotalCharges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the columns which dont explain much variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.drop(['customerID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  Female              0     Yes         No       1           No   \n",
       "1    Male              0      No         No      34          Yes   \n",
       "2    Male              0      No         No       2          Yes   \n",
       "3    Male              0      No         No      45           No   \n",
       "4  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "0  No phone service             DSL             No          Yes   \n",
       "1                No             DSL            Yes           No   \n",
       "2                No             DSL            Yes          Yes   \n",
       "3  No phone service             DSL            Yes           No   \n",
       "4                No     Fiber optic             No           No   \n",
       "\n",
       "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0               No          No          No              No  Month-to-month   \n",
       "1              Yes          No          No              No        One year   \n",
       "2               No          No          No              No  Month-to-month   \n",
       "3              Yes         Yes          No              No        One year   \n",
       "4               No          No          No              No  Month-to-month   \n",
       "\n",
       "  PaperlessBilling              PaymentMethod  MonthlyCharges  TotalCharges  \n",
       "0              Yes           Electronic check           29.85         29.85  \n",
       "1               No               Mailed check           56.95       1889.50  \n",
       "2              Yes               Mailed check           53.85        108.15  \n",
       "3               No  Bank transfer (automatic)           42.30       1840.75  \n",
       "4              Yes           Electronic check           70.70        151.65  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco['SeniorCitizen']=telco['SeniorCitizen'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_backup=telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "encoding=defaultdict(LabelBinarizer)\n",
    "columns_nominal=['gender','Partner','Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','PaymentMethod']\n",
    "for i in columns_nominal:\n",
    "    encoded_df=pd.DataFrame()\n",
    "    d=pd.DataFrame(encoding[i].fit_transform(telco[i]))\n",
    "    test_column=d.columns.values\n",
    "    list1=[i+'_'+str(j) for j in test_column]\n",
    "    d.columns=list1\n",
    "    encoded_df=pd.concat([encoded_df,d],axis=1)\n",
    "    telco.drop(i,axis=1, inplace=True)\n",
    "    telco=pd.concat([telco,encoded_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "y['Churn']=lb_make.fit_transform(y[\"Churn\"])\n",
    "lb_contract = LabelEncoder()\n",
    "telco['Contract']=lb_make.fit_transform(telco[\"Contract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Contract</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>Partner_0</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>PhoneService_0</th>\n",
       "      <th>MultipleLines_0</th>\n",
       "      <th>MultipleLines_1</th>\n",
       "      <th>MultipleLines_2</th>\n",
       "      <th>InternetService_0</th>\n",
       "      <th>InternetService_1</th>\n",
       "      <th>InternetService_2</th>\n",
       "      <th>OnlineSecurity_0</th>\n",
       "      <th>OnlineSecurity_1</th>\n",
       "      <th>OnlineSecurity_2</th>\n",
       "      <th>OnlineBackup_0</th>\n",
       "      <th>OnlineBackup_1</th>\n",
       "      <th>OnlineBackup_2</th>\n",
       "      <th>DeviceProtection_0</th>\n",
       "      <th>DeviceProtection_1</th>\n",
       "      <th>DeviceProtection_2</th>\n",
       "      <th>TechSupport_0</th>\n",
       "      <th>TechSupport_1</th>\n",
       "      <th>TechSupport_2</th>\n",
       "      <th>StreamingTV_0</th>\n",
       "      <th>StreamingTV_1</th>\n",
       "      <th>StreamingTV_2</th>\n",
       "      <th>StreamingMovies_0</th>\n",
       "      <th>StreamingMovies_1</th>\n",
       "      <th>StreamingMovies_2</th>\n",
       "      <th>PaperlessBilling_0</th>\n",
       "      <th>PaymentMethod_0</th>\n",
       "      <th>PaymentMethod_1</th>\n",
       "      <th>PaymentMethod_2</th>\n",
       "      <th>PaymentMethod_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SeniorCitizen  tenure  Contract  MonthlyCharges  TotalCharges  gender_0  \\\n",
       "0             0       1         0           29.85         29.85         0   \n",
       "1             0      34         1           56.95       1889.50         1   \n",
       "2             0       2         0           53.85        108.15         1   \n",
       "3             0      45         1           42.30       1840.75         1   \n",
       "4             0       2         0           70.70        151.65         0   \n",
       "\n",
       "   Partner_0  Dependents_0  PhoneService_0  MultipleLines_0  MultipleLines_1  \\\n",
       "0          1             0               0                0                1   \n",
       "1          0             0               1                1                0   \n",
       "2          0             0               1                1                0   \n",
       "3          0             0               0                0                1   \n",
       "4          0             0               1                1                0   \n",
       "\n",
       "   MultipleLines_2  InternetService_0  InternetService_1  InternetService_2  \\\n",
       "0                0                  1                  0                  0   \n",
       "1                0                  1                  0                  0   \n",
       "2                0                  1                  0                  0   \n",
       "3                0                  1                  0                  0   \n",
       "4                0                  0                  1                  0   \n",
       "\n",
       "   OnlineSecurity_0  OnlineSecurity_1  OnlineSecurity_2  OnlineBackup_0  \\\n",
       "0                 1                 0                 0               0   \n",
       "1                 0                 0                 1               1   \n",
       "2                 0                 0                 1               0   \n",
       "3                 0                 0                 1               1   \n",
       "4                 1                 0                 0               1   \n",
       "\n",
       "   OnlineBackup_1  OnlineBackup_2  DeviceProtection_0  DeviceProtection_1  \\\n",
       "0               0               1                   1                   0   \n",
       "1               0               0                   0                   0   \n",
       "2               0               1                   1                   0   \n",
       "3               0               0                   0                   0   \n",
       "4               0               0                   1                   0   \n",
       "\n",
       "   DeviceProtection_2  TechSupport_0  TechSupport_1  TechSupport_2  \\\n",
       "0                   0              1              0              0   \n",
       "1                   1              1              0              0   \n",
       "2                   0              1              0              0   \n",
       "3                   1              0              0              1   \n",
       "4                   0              1              0              0   \n",
       "\n",
       "   StreamingTV_0  StreamingTV_1  StreamingTV_2  StreamingMovies_0  \\\n",
       "0              1              0              0                  1   \n",
       "1              1              0              0                  1   \n",
       "2              1              0              0                  1   \n",
       "3              1              0              0                  1   \n",
       "4              1              0              0                  1   \n",
       "\n",
       "   StreamingMovies_1  StreamingMovies_2  PaperlessBilling_0  PaymentMethod_0  \\\n",
       "0                  0                  0                   1                0   \n",
       "1                  0                  0                   0                0   \n",
       "2                  0                  0                   1                0   \n",
       "3                  0                  0                   0                1   \n",
       "4                  0                  0                   1                0   \n",
       "\n",
       "   PaymentMethod_1  PaymentMethod_2  PaymentMethod_3  \n",
       "0                0                1                0  \n",
       "1                0                0                1  \n",
       "2                0                0                1  \n",
       "3                0                0                0  \n",
       "4                0                1                0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "#enc.fit(telco['gender_lb'])\n",
    "enc.fit(telco['MultipleLines_LE'].values.reshape(-1,1))\n",
    "X=enc.transform(telco['MultipleLines_LE'].values.reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4930, 38), (2113, 38))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(telco,y,test_size=0.30,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-6be9c8f352d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# based on the optimal roc_auc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m sfs1 = SFS(RandomForestClassifier(n_jobs=4), \n\u001b[0m\u001b[0;32m      7\u001b[0m            \u001b[0mk_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m            \u001b[0mforward\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# step forward feature selection\n",
    "# I indicate that I want to select 10 features from\n",
    "# the total, and that I want to select those features\n",
    "# based on the optimal roc_auc\n",
    "\n",
    "sfs1 = SFS(RandomForestClassifier(n_jobs=4), \n",
    "           k_features=10, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='roc_auc',\n",
    "           cv=3)\n",
    "\n",
    "sfs1 = sfs1.fit(np.array(X_train.fillna(0)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sfs1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-6c08d9f48fbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_feat\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msfs1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_feature_idx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mselected_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sfs1' is not defined"
     ]
    }
   ],
   "source": [
    "selected_feat= X_train.columns[list(sfs1.k_feature_idx_)]\n",
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8457613400391941\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8541509600559666\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# using selected features\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "run_randomForests(X_train.fillna(0),\n",
    "                  X_test.fillna(0),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive feature selection\n",
    "\n",
    "Sequential feature selection algorithms are a family of greedy search algorithms that are used to reduce an initial d-dimensional feature space to a k-dimensional feature subspace where k < d.\n",
    "\n",
    "In an exhaustive feature selection the best subset of features is selected, over all possible feature subsets, by optimizing a specified performance metric for a certain machine learning algorithm. For example, if the classifier is a logistic regression and the dataset consists of 4 features, the algorithm will evaluate all **15** feature combinations as follows:\n",
    "\n",
    "- all possible combinations of 1 feature\n",
    "- all possible combinations of 2 features\n",
    "- all possible combinations of 3 features\n",
    "- all the 4 features\n",
    "\n",
    "and select the one that results in the best performance (e.g., classification accuracy) of the logistic regression classifier.\n",
    "\n",
    "This is another greedy algorithm as it evaluates all possible feature combinations. It is quite computationally expensive, and sometimes, if feature space is big, even unfeasible.\n",
    "\n",
    "There is a special package for python that implements this type of feature selection: mlxtend.\n",
    "\n",
    "In the mlxtend implementation of the exhaustive feature selection, the stopping criteria is an arbitrarily set number of features. So the search will finish when we reach the desired number of selected features. \n",
    "\n",
    "This is somewhat arbitrary because we may be selecting a subopimal number of features, or likewise, a high number of features. \n",
    "\n",
    "Here I will use the Exhaustive feature selection algorithm from mlxtend in a classification (Paribas) and regression (House Price) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "Features: 15/15"
     ]
    }
   ],
   "source": [
    "# exhaustive feature selection\n",
    "# I indicate that I want to select 10 features from\n",
    "# the total, and that I want to select those features\n",
    "# based on the optimal roc_auc\n",
    "\n",
    "# in order to shorter search time for the demonstration\n",
    "# i will ask the algorithm to try all possible 1,2,3 and 4\n",
    "# feature combinations from a dataset of 4 features\n",
    "\n",
    "# if you have access to a multicore or distributed computer\n",
    "# system you can try more greedy searches\n",
    "\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "efs1 = EFS(RandomForestClassifier(n_jobs=4, random_state=0), \n",
    "           min_features=1,\n",
    "           max_features=4, \n",
    "           scoring='roc_auc',\n",
    "           print_progress=True,\n",
    "           cv=2)\n",
    "\n",
    "efs1 = efs1.fit(np.array(X_train[X_train.columns[0:4]].fillna(0)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'efs1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-99f4d5909682>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_feat\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mefs1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_idx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mselected_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'efs1' is not defined"
     ]
    }
   ],
   "source": [
    "selected_feat= X_train.columns[list(efs1.best_idx_)]\n",
    "selected_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regularisation\n",
    "\n",
    "Regularisation consists in adding a penalty to the different parameters of the machine learning model to reduce the freedom of the model and in other words to avoid overfitting. In linear model regularisation, the penalty is applied over the coefficients that multiply each of the predictors. From the different types of regularisation, Lasso or l1 has the property that is able to shrink some of the coefficients to zero. Therefore, that feature can be removed from the model.\n",
    "\n",
    "I will demonstrate how to select features using the Lasso regularisation on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I will do the model fitting and feature selection\n",
    "# altogether in one line of code\n",
    "\n",
    "# first I specify the Logistic Regression model, and I\n",
    "# make sure I select the Lasso (l1) penalty.\n",
    "\n",
    "# Then I use the selectFromModel object from sklearn, which\n",
    "# will select in theory the features which coefficients are non-zero\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1'))\n",
    "sel_.fit(X_train.fillna(0), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False, False,  True,  True, False,  True,  True,  True,\n",
       "        True, False, False,  True, False, False,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 38\n",
      "selected features: 27\n",
      "features with coefficients shrank to zero: 10\n"
     ]
    }
   ],
   "source": [
    "# Now I make a list with the selected features\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of features which coefficient was shrank to zero:\n",
    "np.sum(sel_.estimator_.coef_ == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Partner_0', 'MultipleLines_1', 'MultipleLines_2', 'InternetService_2',\n",
       "       'OnlineBackup_2', 'DeviceProtection_1', 'DeviceProtection_2',\n",
       "       'TechSupport_2', 'StreamingTV_0', 'PaymentMethod_0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can identify the removed features like this:\n",
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection by random shuffling\n",
    "\n",
    "A popular method of feature selection consists in random shuffling the values of a specific variable and determining how that permutation affects the performance metric of the machine learning algorithm. In other words, the idea is to permute the values of each feature, one at the time, and measure how much the permutation decreases the accuracy, or the roc_auc, or the mse of the machine learning model. If the variables are important, this is, highly predictive, a random permutation of their values will decrease dramatically any of these metrics. Contrarily, non-important / non-predictive variables, should have little to no effect on the model performance metric we are assessing.\n",
    "\n",
    "I will demonstrate how to select features based on random shuffling using on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle.\n",
    "\n",
    "**Note** For the demonstration, I will continue to use Random Forests, but this method is useful for any machine learning algorithm. In fact, the importance of the features are determined specifically for the algorithm used. Therefore, different algorithms may return different subsets of important features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc score:  0.8281300951177155\n",
      "test auc score:  0.8401853776265416\n"
     ]
    }
   ],
   "source": [
    "# The first step to determine feature importance by feature shuffling\n",
    "# is to build the machine learning model for which we want to \n",
    "# select features\n",
    "\n",
    "# In this case, I will build Random Forests, but remember that \n",
    "# you can use this procedure for any other machine learning algorithm\n",
    "\n",
    "# I build few and shallow trees to avoid overfitting\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=2, random_state=2909, n_jobs=4)\n",
    "\n",
    "rf.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "# print roc-auc in train and testing sets\n",
    "print('train auc score: ',\n",
    "      roc_auc_score(y_train, (rf.predict_proba(X_train.fillna(0)))[:, 1]))\n",
    "print('test auc score: ',\n",
    "      roc_auc_score(y_test, (rf.predict_proba(X_test.fillna(0)))[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, I will shuffle one by one, each feature of the dataset\n",
    "# and then use the dataset with the shuffled variable to make predictions\n",
    "# using the random forests I trained in the previous cell\n",
    "\n",
    "# overall train roc-auc: using all the features\n",
    "train_auc = roc_auc_score(y_train, (rf.predict_proba(X_train.fillna(0)))[:, 1])\n",
    "\n",
    "# dictionary to capture the features and the drop in auc that they\n",
    "# cause when shuffled\n",
    "feature_dict = {}\n",
    "\n",
    "# selection  logic\n",
    "for feature in X_train.columns:\n",
    "    X_train_c = X_train.copy()\n",
    "    \n",
    "    # shuffle individual feature\n",
    "    X_train_c[feature] = X_train_c[feature].sample(frac=1).reset_index(\n",
    "        drop=True)\n",
    "    \n",
    "    # make prediction with shuffled feature and calculate roc-auc\n",
    "    shuff_auc = roc_auc_score(y_train,\n",
    "                              (rf.predict_proba(X_train_c.fillna(0)))[:, 1])\n",
    "    \n",
    "    # save the drop in roc-auc\n",
    "    feature_dict[feature] = (train_auc - shuff_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contract': 0.051356980875550406,\n",
       " 'Dependents_0': 0.0,\n",
       " 'DeviceProtection_0': -0.0002095670046151632,\n",
       " 'DeviceProtection_1': -0.001750144721258895,\n",
       " 'DeviceProtection_2': 0.0,\n",
       " 'InternetService_0': 0.0008910580850058913,\n",
       " 'InternetService_1': 0.008325004115925738,\n",
       " 'InternetService_2': -0.0004869007344935339,\n",
       " 'MonthlyCharges': 0.0011482105017180944,\n",
       " 'MultipleLines_0': -0.00019437791102161484,\n",
       " 'MultipleLines_1': 0.0,\n",
       " 'MultipleLines_2': 6.6916985762555115e-06,\n",
       " 'OnlineBackup_0': 0.0014274561454753476,\n",
       " 'OnlineBackup_1': -0.0017273079721498164,\n",
       " 'OnlineBackup_2': 0.0,\n",
       " 'OnlineSecurity_0': 0.008495589320898889,\n",
       " 'OnlineSecurity_1': -0.0008914829547566061,\n",
       " 'OnlineSecurity_2': 0.0002074426558607012,\n",
       " 'PaperlessBilling_0': 0.0,\n",
       " 'Partner_0': 6.999729145529265e-05,\n",
       " 'PaymentMethod_0': -6.59610288219481e-05,\n",
       " 'PaymentMethod_1': 4.142480070945531e-05,\n",
       " 'PaymentMethod_2': 0.006054712602167944,\n",
       " 'PaymentMethod_3': 3.781340782726961e-05,\n",
       " 'PhoneService_0': 0.0,\n",
       " 'SeniorCitizen': 0.0,\n",
       " 'StreamingMovies_0': -0.0003566781558528298,\n",
       " 'StreamingMovies_1': -0.0023450685899103485,\n",
       " 'StreamingMovies_2': 0.0,\n",
       " 'StreamingTV_0': 0.0,\n",
       " 'StreamingTV_1': -0.0007101697885742997,\n",
       " 'StreamingTV_2': 2.8678708183460522e-05,\n",
       " 'TechSupport_0': 0.0024823015194403997,\n",
       " 'TechSupport_1': -0.0013712671209231697,\n",
       " 'TechSupport_2': 0.0,\n",
       " 'TotalCharges': 0.005730324547380983,\n",
       " 'gender_0': 0.0,\n",
       " 'tenure': 0.014414449820226993}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's have a look at the generated dictionary\n",
    "feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>auc_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contract</td>\n",
       "      <td>0.051357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dependents_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeviceProtection_0</td>\n",
       "      <td>-0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeviceProtection_1</td>\n",
       "      <td>-0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeviceProtection_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  auc_drop\n",
       "0            Contract  0.051357\n",
       "1        Dependents_0  0.000000\n",
       "2  DeviceProtection_0 -0.000210\n",
       "3  DeviceProtection_1 -0.001750\n",
       "4  DeviceProtection_2  0.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I will transform the dictionary into a pandas dataframe\n",
    "# for easy manipulation\n",
    "\n",
    "feature_importance = pd.Series(feature_dict).reset_index()\n",
    "feature_importance.columns = ['feature', 'auc_drop']\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid method: Recursive feature elimination\n",
    "\n",
    "This method consists of the following steps:\n",
    "\n",
    "1) Rank the features according to their importance derived from a machine learning algorithm: it can be tree importance, or LASSO / Ridge, or the linear / logistic regression coefficients.\n",
    "\n",
    "2) Remove one feature -the least important- and build a machine learning algorithm utilising the remaining features.\n",
    "\n",
    "3) Calculate a performance metric of your choice: roc-auc, mse, rmse, accuracy.\n",
    "\n",
    "4) If the metric decreases by more of an arbitrarily set threshold, then that feature is important and should be kept. Otherwise, we can remove that feature.\n",
    "\n",
    "5) Repeat steps 2-4 until all features have been removed (and therefore evaluated) and the drop in performance assessed.\n",
    "\n",
    "\n",
    "I call this a hybrid method because:\n",
    "\n",
    "- it combines the importance derived from the machine learning algorithm like embedded methods,\n",
    "- and it removes as well one feature at a time, and calculates a new metric based on the new subset of features and the machine learning algorithm of choice, like wrapper methods.\n",
    "\n",
    "The difference between this method and the step backwards feature selection we learned in previous lectures lies in that it does not remove all features first in order to determine which one to remove. It removes the least important one, based on the machine learning model derived important. And then, it makes an assessment as to whether that feature should be removed or not. So it removes each feature only once during selection, whereas step backward feature selection removes all the features at each step of selection.\n",
    "\n",
    "This method is therefore faster than wrapper methods and generally better than embedded methods. In practice it works extremely well. It does also account for correlations (depending on how stringent you set the arbitrary performance drop threshold). On the downside, the drop in performance assessed to decide whether the feature should be kept or removed, is set arbitrarily. The smaller the drop the more features will be selected, and vice versa.\n",
    "\n",
    "I will demonstrate how to select features using this method on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle.\n",
    "\n",
    "**Note** For the demonstration, I will use XGBoost, but this method is useful for any machine learning algorithm. In fact, the importance of the features are determined specifically for the algorithm used. Therefore, different algorithms may return different subsets of important features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields SeniorCitizen",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-c8f905389fdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel_all_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# calculate the roc-auc in the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[1;32m--> 541\u001b[1;33m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    342\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[0;32m    343\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m                                                                 feature_types)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[1;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    212\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[0;32m    213\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields SeniorCitizen"
     ]
    }
   ],
   "source": [
    "# the first step of this procedure  consists in building\n",
    "# a machine learning algorithm using all the available features\n",
    "# and then determine the importance of the features according\n",
    "# to the algorithm\n",
    "\n",
    "# set the seed for reproducibility\n",
    "import xgboost as xgb\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model using all the features\n",
    "model_all_features = xgb.XGBClassifier(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "model_all_features.fit(X_train, y_train)\n",
    "\n",
    "# calculate the roc-auc in the test set\n",
    "y_pred_test = model_all_features.predict_proba(X_test)[:, 1]\n",
    "auc_score_all = roc_auc_score(y_test, y_pred_test)\n",
    "print('Test all features xgb ROC AUC=%f' % (auc_score_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final step consists in removing one at a time\n",
    "# all the features, from the least to the most\n",
    "# important, and build an xgboost at each round.\n",
    "\n",
    "# once we build the model, we calculate the new roc-auc\n",
    "# if the new roc-auc is smaller than the original one\n",
    "# (with all the features), then that feature that was removed\n",
    "# was important, and we should keep it.\n",
    "# otherwise, we should remove the feature\n",
    "\n",
    "# recursive feature elimination:\n",
    "\n",
    "# first we arbitrarily set the drop in roc-auc\n",
    "# if the drop is below this threshold,\n",
    "# the feature will be removed\n",
    "tol = 0.0005\n",
    "\n",
    "print('doing recursive feature elimination')\n",
    "\n",
    "# we initialise a list where we will collect the\n",
    "# features we should remove\n",
    "features_to_remove = []\n",
    "\n",
    "# set a counter to know how far ahead the loop is going\n",
    "count = 1\n",
    "\n",
    "# now we loop over all the features, in order of importance:\n",
    "# remember that features is the list of ordered features\n",
    "# by importance\n",
    "for feature in features:\n",
    "    print()\n",
    "    print('testing feature: ', feature, ' which is feature ', count,\n",
    "          ' out of ', len(features))\n",
    "    count = count + 1\n",
    "\n",
    "    # initialise model\n",
    "    model_int = xgb.XGBClassifier(\n",
    "        nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "    # fit model with all variables minus the removed features\n",
    "    # and the feature to be evaluated\n",
    "    model_int.fit(\n",
    "        X_train.drop(features_to_remove + [feature], axis=1), y_train)\n",
    "\n",
    "    # make a prediction over the test set\n",
    "    y_pred_test = model_int.predict_proba(\n",
    "        X_test.drop(features_to_remove + [feature], axis=1))[:, 1]\n",
    "\n",
    "    # calculate the new roc-auc\n",
    "    auc_score_int = roc_auc_score(y_test, y_pred_test)\n",
    "    print('New Test ROC AUC={}'.format((auc_score_int)))\n",
    "\n",
    "    # print the original roc-auc with all the features\n",
    "    print('All features Test ROC AUC={}'.format((auc_score_all)))\n",
    "\n",
    "    # determine the drop in the roc-auc\n",
    "    diff_auc = auc_score_all - auc_score_int\n",
    "\n",
    "    # compare the drop in roc-auc with the tolerance\n",
    "    # we set previously\n",
    "    if diff_auc >= tol:\n",
    "        print('Drop in ROC AUC={}'.format(diff_auc))\n",
    "        print('keep: ', feature)\n",
    "        print\n",
    "    else:\n",
    "        print('Drop in ROC AUC={}'.format(diff_auc))\n",
    "        print('remove: ', feature)\n",
    "        print\n",
    "        # if the drop in the roc is small and we remove the\n",
    "        # feature, we need to set the new roc to the one based on\n",
    "        # the remaining features\n",
    "        auc_score_all = auc_score_int\n",
    "        \n",
    "        # and append the feature to remove to the collecting\n",
    "        # list\n",
    "        features_to_remove.append(feature)\n",
    "\n",
    "# now the loop is finished, we evaluated all the features\n",
    "print('DONE!!')\n",
    "print('total features to remove: ', len(features_to_remove))\n",
    "\n",
    "# determine the features to keep (those we won't remove)\n",
    "features_to_keep = [x for x in features if x not in features_to_remove]\n",
    "print('total features to keep: ', len(features_to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the xgb model built with 56 features shows a similar performance than the one built with the total features (0.715 vs 0.713).\n",
    "\n",
    "We may not be able to get this right from the beginning though, as we did here. This method of feature selection does require that you try a few different tolerances / thresholds until you find the right number of features.\n",
    "\n",
    "Why don't you go ahead and try different values? Try with lower and bigger thresholds and get a feeling of how much this affects the number of selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid method: Recursive feature addition\n",
    "\n",
    "This method consists of the following steps:\n",
    "\n",
    "1) Rank the features according to their importance derived from a machine learning algorithm: it can be tree importance, or LASSO / Ridge, or the linear / logistic regression coefficients.\n",
    "\n",
    "2) Build a machine learning model with only 1 feature, the most important one, and calculate the model metric for performance.\n",
    "\n",
    "3) Add one feature -the most important- and build a machine learning algorithm utilising the added and any feature from previous rounds.\n",
    "\n",
    "4) Calculate a performance metric of your choice: roc-auc, mse, rmse, accuracy.\n",
    "\n",
    "5) If the metric increases by more than an arbitrarily set threshold, then that feature is important and should be kept. Otherwise, we can remove that feature.\n",
    "\n",
    "6) Repeat steps 2-5 until all features have been removed (and therefore evaluated) and the drop in performance assessed.\n",
    "\n",
    "\n",
    "I call this a hybrid method because:\n",
    "\n",
    "- it combines the importance derived from the machine learning algorithm like embedded methods,\n",
    "- and it adds as well one feature at a time, and calculates a new metric based on the new subset of features and the machine learning algorithm of choice, like wrapper methods.\n",
    "\n",
    "The difference between this method and the step forward feature selection we learned in previous lectures lies in that it does not add all possible features first, in order to determine which one to keep. It adds the most important one, based on the machine learning model derived important. And then, it makes an assessment as to whether that feature should be kept or not. And then it moves to the next feature.\n",
    "\n",
    "This method is therefore faster than wrapper methods and generally better than embedded methods. In practice it works extremely well. It does also account for correlations (depending on how stringent you set the arbitrary performance drop threshold). On the downside, the increase in performance assessed to decide whether the feature should be kept or removed, is set arbitrarily. The smaller the increase the more features will be selected, and vice versa.\n",
    "\n",
    "I will demonstrate how to select features using this method on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle.\n",
    "\n",
    "**Note** For the demonstration, I will use XGBoost, but this method is useful for any machine learning algorithm. In fact, the importance of the features are determined specifically for the algorithm used. Therefore, different algorithms may return different subsets of important features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first step of this procedure  consists in building\n",
    "# a machine learning algorithm using all the available features\n",
    "# and then determine the importance of the features according\n",
    "# to the algorithm\n",
    "\n",
    "# set the seed for reproducibility\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model using all the features\n",
    "model_all_features = xgb.XGBClassifier(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "model_all_features.fit(X_train, y_train)\n",
    "\n",
    "# calculate the roc-auc in the test set\n",
    "y_pred_test = model_all_features.predict_proba(X_test)[:, 1]\n",
    "auc_score_all = roc_auc_score(y_test, y_pred_test)\n",
    "print('Test all features xgb ROC AUC=%f' % (auc_score_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the second step consist of deriving the importance of \n",
    "# each feature and ranking them from the most to the least\n",
    "# important\n",
    "\n",
    "# get feature name and importance\n",
    "features = pd.Series(model_all_features.feature_importances_)\n",
    "features.index = X_train.columns\n",
    "\n",
    "# sort the features by importance\n",
    "features.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# plot\n",
    "features.plot.bar(figsize=(20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the list of ordered features\n",
    "features = list(features.index)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we need to build a machine learning\n",
    "# algorithm using only the most important feature\n",
    "\n",
    "# set the seed for reproducibility\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model using all the features\n",
    "model_one_feature = xgb.XGBClassifier(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "# train using only the most important feature\n",
    "model_one_feature.fit(X_train[features[0]].to_frame(), y_train)\n",
    "\n",
    "# calculate the roc-auc in the test set\n",
    "y_pred_test = model_one_feature.predict_proba(X_test[features[0]].to_frame())[:, 1]\n",
    "auc_score_first = roc_auc_score(y_test, y_pred_test)\n",
    "print('Test one feature xgb ROC AUC=%f' % (auc_score_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final step consists in adding one at a time\n",
    "# all the features, from the most to the least\n",
    "# important, and build an xgboost at each round.\n",
    "\n",
    "# once we build the model, we calculate the new roc-auc\n",
    "# if the new roc-auc is bigger than the original one\n",
    "# (with one feature), then that feature that was added\n",
    "# was important, and we should keep it.\n",
    "# otherwise, we should remove the feature\n",
    "\n",
    "# recursive feature addition:\n",
    "\n",
    "# first we arbitrarily set the increase in roc-auc\n",
    "# if the increase is above this threshold,\n",
    "# the feature will be kept\n",
    "tol = 0.001\n",
    "\n",
    "print('doing recursive feature addition')\n",
    "\n",
    "# we initialise a list where we will collect the\n",
    "# features we should keep\n",
    "features_to_keep = [features[0]]\n",
    "\n",
    "# set a counter to know how far ahead the loop is going\n",
    "count = 1\n",
    "\n",
    "# now we loop over all the features, in order of importance:\n",
    "# remember that features is the list of ordered features\n",
    "# by importance\n",
    "for feature in features[1:]:\n",
    "    print()\n",
    "    print('testing feature: ', feature, ' which is feature ', count,\n",
    "          ' out of ', len(features))\n",
    "    count = count + 1\n",
    "\n",
    "    # initialise model\n",
    "    model_int = xgb.XGBClassifier(\n",
    "        nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "    # fit model with the selected features\n",
    "    # and the feature to be evaluated\n",
    "    model_int.fit(\n",
    "        X_train[features_to_keep + [feature] ], y_train)\n",
    "\n",
    "    # make a prediction over the test set\n",
    "    y_pred_test = model_int.predict_proba(\n",
    "        X_test[features_to_keep + [feature] ])[:, 1]\n",
    "\n",
    "    # calculate the new roc-auc\n",
    "    auc_score_int = roc_auc_score(y_test, y_pred_test)\n",
    "    print('New Test ROC AUC={}'.format((auc_score_int)))\n",
    "\n",
    "    # print the original roc-auc with one feature\n",
    "    print('All features Test ROC AUC={}'.format((auc_score_first)))\n",
    "\n",
    "    # determine the increase in the roc-auc\n",
    "    diff_auc = auc_score_int - auc_score_first\n",
    "\n",
    "    # compare the increase in roc-auc with the tolerance\n",
    "    # we set previously\n",
    "    if diff_auc >= tol:\n",
    "        print('Increase in ROC AUC={}'.format(diff_auc))\n",
    "        print('keep: ', feature)\n",
    "        print\n",
    "        # if the increase in the roc is bigger than the threshold\n",
    "        # we keep the feature and re-adjust the roc-auc to the new value\n",
    "        # considering the added feature\n",
    "        auc_score_first = auc_score_int\n",
    "        \n",
    "        # and we append the feature to keep to the list\n",
    "        features_to_keep.append(feature)\n",
    "    else:\n",
    "        # we ignore the feature\n",
    "        print('Increase in ROC AUC={}'.format(diff_auc))\n",
    "        print('remove: ', feature)\n",
    "        print\n",
    "\n",
    "\n",
    "# now the loop is finished, we evaluated all the features\n",
    "print('DONE!!')\n",
    "print('total features to keep: ', len(features_to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a threshold / tolerance of 0.001 we selected 8 features. The model built with 8 features is far more predictive than the one built with 1 feature. In addition, the model built with 8 features is more predictive than the one built with all the features (0.717 vs 0.713). \n",
    "And if you remember from the previous lecture where we selected 56 features by recursive feature elimination, the roc-auc was 0.715, which indicates that many of those features are still redundant, as a model built with 8 features seems to perform better.\n",
    "\n",
    "Here we got a good uplift with just one try. However, in practice you may need to run a few runs of these method and find the right threshold, depending on how many features you are willing to include in your model and how accurate you would like it to be.\n",
    "\n",
    "Why don't you give it a go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying  KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
      "           weights='uniform')>\n",
      "Confusion Metrics:\n",
      " [[3386  249]\n",
      " [ 748  547]]\n",
      "Train accuracy: 0.7977687626774848\n",
      "Test accuracy: 0.7870326549929011\n",
      "Train precision: 0.7531236856755962\n",
      "Test precision: 0.7433297515548174\n",
      "Train recall: 0.6769465673179567\n",
      "Test recall: 0.6691876484345461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNNC=KNeighborsClassifier(n_neighbors=17)\n",
    "KNNC.fit(X_train,y_train)\n",
    "KNNC_Train_Prediction=KNNC.predict(X_train)\n",
    "KNNC_Test_Prediction=KNNC.predict(X_test)\n",
    "\n",
    "print(KNNC.get_params)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CF_train=confusion_matrix(y_train,KNNC_Train_Prediction)\n",
    "CF_test=confusion_matrix(y_test,KNNC_Test_Prediction)\n",
    "print('Confusion Metrics:\\n',CF_train)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,precision_score,recall_score\n",
    "train_accuracy=accuracy_score(y_train,KNNC_Train_Prediction)\n",
    "test_accuracy=accuracy_score(y_test,KNNC_Test_Prediction)\n",
    "print('Train accuracy:',train_accuracy)\n",
    "print('Test accuracy:',test_accuracy)\n",
    "\n",
    "train_precision=precision_score(y_train,KNNC_Train_Prediction,average='macro')\n",
    "test_precision=precision_score(y_test,KNNC_Test_Prediction,average='macro')\n",
    "print('Train precision:',train_precision)\n",
    "print('Test precision:',test_precision)\n",
    "\n",
    "train_recall=recall_score(y_train,KNNC_Train_Prediction,average='macro')\n",
    "test_recall=recall_score(y_test,KNNC_Test_Prediction,average='macro')\n",
    "print('Train recall:',train_recall)\n",
    "print('Test recall:',test_recall)\n",
    "\n",
    "\n",
    "#train_roc_auc_score=roc_auc_score(y_train,KNNC_Train_Prediction)\n",
    "#test_roc_auc_score=roc_auc_score(y_test,KNNC_Test_Prediction)\n",
    "#print('Train roc score:',train_roc_auc_score)\n",
    "#print('Test roc score:',test_roc_auc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xffbb630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pre requisite:\n",
    "#We should convert the output variable into numeric using lable_binarize\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNNC=KNeighborsClassifier()\n",
    "KNNC.fit(X_train,y_train)\n",
    "KNNC_Train_Prediction=KNNC.predict(X_train)\n",
    "KNNC_Test_Prediction=KNNC.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,_=roc_curve(y_test,KNNC_Test_Prediction,drop_intermediate=False)\n",
    "\n",
    "# Plotting the ROC graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc_curve_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6725638622301009"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,KNNC_Test_Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************** precision ***********************************\n",
      "Best Parameters: {'n_neighbors': 13}\n",
      "CV Results Keys: \n",
      " dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_n_neighbors', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n",
      "CV Results: \n",
      " {'mean_fit_time': array([0.02233458, 0.0196677 , 0.0196677 , 0.02000125]), 'std_fit_time': array([4.71420930e-03, 4.71426560e-04, 9.42853099e-04, 1.12391596e-07]), 'mean_score_time': array([0.0336686 , 0.0346686 , 0.03733548, 0.0373354 ]), 'std_score_time': array([0.00235713, 0.00094297, 0.00047148, 0.00047154]), 'param_n_neighbors': masked_array(data=[5, 9, 13, 15],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 5}, {'n_neighbors': 9}, {'n_neighbors': 13}, {'n_neighbors': 15}], 'split0_test_score': array([0.68888527, 0.69410137, 0.71319974, 0.71481628]), 'split1_test_score': array([0.67554953, 0.70119108, 0.71360842, 0.70668728]), 'split2_test_score': array([0.68914894, 0.70402879, 0.70579809, 0.70954577]), 'mean_test_score': array([0.68452604, 0.69977202, 0.71087081, 0.71035011]), 'std_test_score': array([0.00635019, 0.00417489, 0.00358865, 0.00336764]), 'rank_test_score': array([4, 3, 1, 2]), 'split0_train_score': array([0.7842591 , 0.77697906, 0.74884061, 0.74161829]), 'split1_train_score': array([0.79013385, 0.7755303 , 0.76450968, 0.76436962]), 'split2_train_score': array([0.78928402, 0.77615521, 0.76298537, 0.75553447]), 'mean_train_score': array([0.78789232, 0.77622152, 0.75877855, 0.75384079]), 'std_train_score': array([0.0025924 , 0.00059331, 0.00705469, 0.00936508])}\n",
      "*********************************** recall ***********************************\n",
      "Best Parameters: {'n_neighbors': 5}\n",
      "CV Results Keys: \n",
      " dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_n_neighbors', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n",
      "CV Results: \n",
      " {'mean_fit_time': array([0.02066787, 0.02100118, 0.02033432, 0.02100126]), 'std_fit_time': array([4.71426560e-04, 1.12391596e-07, 4.71482745e-04, 1.41433584e-03]), 'mean_score_time': array([0.03133504, 0.03300166, 0.03500223, 0.03900218]), 'std_score_time': array([4.71426560e-04, 0.00000000e+00, 0.00000000e+00, 1.94667955e-07]), 'param_n_neighbors': masked_array(data=[5, 9, 13, 15],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 5}, {'n_neighbors': 9}, {'n_neighbors': 13}, {'n_neighbors': 15}], 'split0_test_score': array([0.66406536, 0.64791896, 0.65418729, 0.6531101 ]), 'split1_test_score': array([0.64306014, 0.65453108, 0.65269756, 0.64947745]), 'split2_test_score': array([0.65001025, 0.64002062, 0.63404293, 0.62847812]), 'mean_test_score': array([0.65237955, 0.64749325, 0.64698117, 0.64369473]), 'std_test_score': array([0.00873898, 0.00593092, 0.00916337, 0.01085504]), 'rank_test_score': array([1, 2, 3, 4]), 'split0_train_score': array([0.7364079 , 0.71649493, 0.67672446, 0.66877988]), 'split1_train_score': array([0.74074926, 0.70792339, 0.68051825, 0.67956585]), 'split2_train_score': array([0.73436354, 0.70653992, 0.68214842, 0.67231046]), 'mean_train_score': array([0.73717357, 0.71031941, 0.67979704, 0.67355206]), 'std_train_score': array([0.00266259, 0.00440312, 0.00227229, 0.00449003])}\n",
      "*********************************** f1 ***********************************\n",
      "Best Parameters: {'n_neighbors': 5}\n",
      "CV Results Keys: \n",
      " dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_n_neighbors', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n",
      "CV Results: \n",
      " {'mean_fit_time': array([0.02433467, 0.02133465, 0.02200119, 0.02033448]), 'std_fit_time': array([0.00543696, 0.00188582, 0.00081653, 0.00047154]), 'mean_score_time': array([0.03200181, 0.0376687 , 0.03766878, 0.03866879]), 'std_score_time': array([0.00081653, 0.0044971 , 0.00047143, 0.00124723]), 'param_n_neighbors': masked_array(data=[5, 9, 13, 15],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 5}, {'n_neighbors': 9}, {'n_neighbors': 13}, {'n_neighbors': 15}], 'split0_test_score': array([0.67340011, 0.66126374, 0.67003316, 0.66923638]), 'split1_test_score': array([0.65356264, 0.66841486, 0.66867489, 0.6646386 ]), 'split2_test_score': array([0.66222661, 0.65506129, 0.6490376 , 0.64323768]), 'mean_test_score': array([0.66306346, 0.66158261, 0.66258738, 0.65904397]), 'std_test_score': array([0.00812181, 0.00545568, 0.00959136, 0.01132661]), 'rank_test_score': array([1, 3, 2, 4]), 'split0_train_score': array([0.75419639, 0.736751  , 0.69657403, 0.68799532]), 'split1_train_score': array([0.75909692, 0.72926378, 0.70249696, 0.70156013]), 'split2_train_score': array([0.75399847, 0.72819208, 0.70381844, 0.69329939]), 'mean_train_score': array([0.75576393, 0.73140228, 0.70096315, 0.69428495]), 'std_train_score': array([0.00235817, 0.00380733, 0.00315011, 0.00558149])}\n",
      "*********************************** roc_auc ***********************************\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'roc_auc_macro' is not a valid scoring value. Valid options are ['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'mutual_info_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'v_measure_score']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-e06f4258761c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mKNNGridSearch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNNC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%s_macro'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mKNNGridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best Parameters:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mKNNGridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CV Results Keys: \\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mKNNGridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[1;32m--> 595\u001b[1;33m             self.estimator, scoring=self.scoring)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    340\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[0;32m    341\u001b[0m                                                           six.string_types):\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    274\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    234\u001b[0m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0;32m    235\u001b[0m                              \u001b[1;34m'Valid options are %s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m                              % (scoring, sorted(scorers)))\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'roc_auc_macro' is not a valid scoring value. Valid options are ['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'mutual_info_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'v_measure_score']"
     ]
    }
   ],
   "source": [
    "score=['precision']\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "scores=['precision', 'recall','f1','roc_auc']\n",
    "for score in scores:\n",
    "    print('***********************************',score,'***********************************')\n",
    "    parameters={'n_neighbors':[5,9,13,15]}\n",
    "    KNNGridSearch=GridSearchCV(KNNC,parameters,cv=3,scoring='%s_macro' % score)\n",
    "    KNNGridSearch.fit(X_train,y_train)\n",
    "    print('Best Parameters:',KNNGridSearch.best_params_)\n",
    "    print('CV Results Keys: \\n',KNNGridSearch.cv_results_.keys())\n",
    "    print('CV Results: \\n',KNNGridSearch.cv_results_)\n",
    "    #print('CV Results values: \\n',KNNGridSearch.cv_results_.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
