{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\KASTU1\\\\Desktop\\\\Analytics Path\\\\R\\\\Data'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "%pwd\n",
    "#os.chdir('C:\\\\Users\\\\Prudhvi\\\\Desktop\\\\Prudhvi\\\\Data Science\\\\Data')\n",
    "os.chdir('C:\\\\Users\\\\KASTU1\\\\Desktop\\\\Analytics Path\\\\R\\\\Data')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn=pd.read_csv(\"Teleco_Cust_Attr_1.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 21)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5174    0]\n",
      " [   0 1869]]\n"
     ]
    }
   ],
   "source": [
    "cm_train=confusion_matrix(churn['Churn'],churn['Churn'])\n",
    "print(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Type Conversion\n",
    "churn[\"SeniorCitizen\"]=churn[\"SeniorCitizen\"].astype(object)\n",
    "\n",
    "## Replacing few values \n",
    "churn.loc[churn.OnlineSecurity==\"No internet service\",\"OnlineSecurity\"]=\"No\"\n",
    "churn.loc[churn.OnlineBackup==\"No internet service\",\"OnlineBackup\"]=\"No\"\n",
    "churn.loc[churn.DeviceProtection==\"No internet service\",\"DeviceProtection\"]=\"No\"\n",
    "churn.loc[churn.TechSupport==\"No internet service\",\"TechSupport\"]=\"No\"\n",
    "churn.loc[churn.StreamingTV==\"No internet service\",\"StreamingTV\"]=\"No\"\n",
    "churn.loc[churn.StreamingMovies==\"No internet service\",\"StreamingMovies\"]=\"No\"\n",
    "churn.loc[churn.MultipleLines==\"No phone service\",\"MultipleLines\"]=\"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping few columns\n",
    "churn.drop(\"customerID\", axis = 1, inplace=True)\n",
    "churn.drop(\"gender\",axis=1,inplace=True)\n",
    "#churn.drop(\"PhoneService\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering\n",
    "churn.insert(0, \"Charges\", 0)\n",
    "total_rows = churn['Churn'].count()\n",
    "for i in range(0,total_rows):\n",
    "    churn.loc[i,\"Charges\"]=churn.loc[i,\"tenure\"]*churn.loc[i,\"MonthlyCharges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.drop(\"TotalCharges\", axis = 1,  inplace=True)\n",
    "churn.drop(\"tenure\",axis=1,inplace=True)\n",
    "churn.drop(\"MonthlyCharges\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lc = LabelEncoder()\n",
    "for i in churn.columns:\n",
    "    if(churn[i].dtype.name==\"object\"):\n",
    "        churn[i] = churn[i].astype(\"category\")\n",
    "        churn[i] = lc.fit_transform(churn[i])\n",
    "        churn[i] = churn[i].astype(\"category\")\n",
    "        \n",
    "# master_dataset.head(7)\n",
    "#churn.dtypes\n",
    "churn['SeniorCitizen']=churn['SeniorCitizen'].astype('uint8')\n",
    "churn['Partner']=churn['Partner'].astype('uint8')\n",
    "churn['Dependents']=churn['Dependents'].astype('uint8')\n",
    "churn['PaperlessBilling']=churn['PaperlessBilling'].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5174    0]\n",
      " [   0 1869]]\n"
     ]
    }
   ],
   "source": [
    "cm_train=confusion_matrix(churn['Churn'],churn['Churn'])\n",
    "print(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "columns_labled=['Charges', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService',\n",
    "       'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "       'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "oe = OneHotEncoder()\n",
    "churn_cat=[]\n",
    "churn_ncat=[]\n",
    "for i in columns_labled:\n",
    "    if(churn[i].dtype.name==\"category\"):\n",
    "        if(len(churn[i].unique()) > 2):\n",
    "            churn_cat.append(i) \n",
    "        else:\n",
    "            churn_ncat.append(i)\n",
    "    else:\n",
    "        churn_ncat.append(i)\n",
    "                 \n",
    "churn_cat = churn[churn_cat]\n",
    "churn_ncat = churn[churn_ncat]\n",
    "fn_dataset = pd.merge(churn_cat,churn_ncat,left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5174    0]\n",
      " [   0 1869]]\n"
     ]
    }
   ],
   "source": [
    "cm_train=confusion_matrix(churn['Churn'],churn['Churn'])\n",
    "print(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_cat = pd.get_dummies(churn_cat,drop_first=True)\n",
    "X = fn_dataset.iloc[:,:-1]\n",
    "Y = fn_dataset.iloc[:,-1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['InternetService_1', 'InternetService_2', 'Contract_1', 'Contract_2',\n",
       "       'PaymentMethod_1', 'PaymentMethod_2', 'PaymentMethod_3', 'Charges',\n",
       "       'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService',\n",
       "       'MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
       "       'TechSupport', 'StreamingTV', 'StreamingMovies'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2872    0]\n",
      " [   0 4171]]\n"
     ]
    }
   ],
   "source": [
    "cm_train=confusion_matrix(Y,Y)\n",
    "print(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.6851571374479364\n",
      "                   0         0\n",
      "0    InternetService -0.203381\n",
      "1           Contract -0.651127\n",
      "2      PaymentMethod -0.047005\n",
      "3            Charges  0.000141\n",
      "4      SeniorCitizen  0.399471\n",
      "5            Partner  0.022445\n",
      "6         Dependents -0.154880\n",
      "7       PhoneService  0.182505\n",
      "8      MultipleLines  0.338135\n",
      "9     OnlineSecurity -0.338064\n",
      "10      OnlineBackup  0.151111\n",
      "11  DeviceProtection -0.048127\n",
      "12       TechSupport -0.119825\n",
      "13       StreamingTV  0.476397\n",
      "14   StreamingMovies  0.439444\n",
      "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Confusion Matrix of Train Dataset\n",
      "[[1008 1118]\n",
      " [ 545 2611]]\n",
      "Precision of Train Data 0.700187717886833\n",
      "Rrecall of Train Data 0.8273130544993663\n",
      "Accuracy of Train Data 0.6851571374479364\n",
      "F1 Score of Train Data 0.7584604212055193\n",
      "classification report of Train Dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.47      0.55      2126\n",
      "          1       0.70      0.83      0.76      3156\n",
      "\n",
      "avg / total       0.68      0.69      0.67      5282\n",
      "\n",
      "Confusion Matrix of test Dataset\n",
      "[[356 390]\n",
      " [172 843]]\n",
      "Precision of Test Data 0.683698296836983\n",
      "Rrecall of Test Data 0.8305418719211822\n",
      "Accuracy of Test Data 0.6808631459398069\n",
      "F1 Score of Test Data 0.7500000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.47      0.55      2126\n",
      "          1       0.70      0.83      0.76      3156\n",
      "\n",
      "avg / total       0.68      0.69      0.67      5282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KASTU1\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(penalty='l2',C=5)\n",
    "print(classifier)\n",
    "result=classifier.fit(X_train, y_train)\n",
    "print(classifier.score(X_train, y_train))\n",
    "coefficients = pd.concat([pd.DataFrame(X_train.columns),pd.DataFrame(np.transpose(result.coef_))], axis = 1)\n",
    "print(coefficients)\n",
    "\n",
    "print(result)\n",
    "y_pred_train = result.predict(X_train)\n",
    "y_pred_test = result.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "cm_train=confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusion Matrix of Train Dataset\")\n",
    "print(cm_train)\n",
    "TP=cm_train[1][1]\n",
    "FP=cm_train[0][1]\n",
    "FN=cm_train[1][0]\n",
    "TN=cm_train[0][0]\n",
    "precision_train=TP/(TP+FP)\n",
    "Recall_train=TP/(TP+FN)\n",
    "Accuracy_train=(TP+TN)/(TP+FP+TN+FN)\n",
    "F1_Score_train=(2*precision_train*Recall_train)/(precision_train+Recall_train)\n",
    "print(\"Precision of Train Data\",+precision_train)\n",
    "print(\"Rrecall of Train Data\",+Recall_train)\n",
    "print(\"Accuracy of Train Data\",+Accuracy_train)\n",
    "print(\"F1 Score of Train Data\",+F1_Score_train)\n",
    "\n",
    "print(\"classification report of Train Dataset\")\n",
    "classificaiton_report_train=classification_report(y_train,y_pred_train)\n",
    "print(classificaiton_report_train)\n",
    "\n",
    "cm_test=confusion_matrix(y_test,y_pred_test)\n",
    "print(\"Confusion Matrix of test Dataset\")\n",
    "print(cm_test)\n",
    "TP=cm_test[1][1]\n",
    "FP=cm_test[0][1]\n",
    "FN=cm_test[1][0]\n",
    "TN=cm_test[0][0]\n",
    "precision_test=TP/(TP+FP)\n",
    "Recall_test=TP/(TP+FN)\n",
    "Accuracy_test=(TP+TN)/(TP+FP+TN+FN)\n",
    "F1_Score_test=(2*precision_test*Recall_test)/(precision_test+Recall_test)\n",
    "print(\"Precision of Test Data\",+precision_test)\n",
    "print(\"Rrecall of Test Data\",+Recall_test)\n",
    "print(\"Accuracy of Test Data\",+Accuracy_test)\n",
    "print(\"F1 Score of Test Data\",+F1_Score_test)\n",
    "classificaiton_report_TEST=classification_report(y_test,y_pred_test)\n",
    "print(classificaiton_report_train)\n",
    "#print(\"classification report of Train Dataset\")\n",
    "#classificaiton_report_test=classification_report(y_test,y_pred_test)\n",
    "#print(classificaiton_report_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
