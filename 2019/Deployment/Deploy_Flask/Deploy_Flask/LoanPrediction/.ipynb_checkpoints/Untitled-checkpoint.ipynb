{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Office\n",
    "#os.chdir('C:\\\\Users\\\\Administrator\\\\Desktop\\\\Data\\\\Loan Prediction')\n",
    "#data = pd.read_csv('LoanTrain.csv')\n",
    "\n",
    "# Personal\n",
    "os.chdir('C:\\\\Users\\\\prudi\\\\Desktop\\\\Data Sets\\\\Loan Prediction')\n",
    "data = pd.read_csv('Loan Prediction Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Handling the Missing Values\n",
    "\n",
    "data.loc[data['Gender'].isnull(),'Gender']='Trasgender'\n",
    "data.loc[data['Dependents'].isnull(),'Dependents']='0'\n",
    "data.loc[data['Married'].isnull(),'Married']='No'\n",
    "data.loc[data['Self_Employed'].isnull(),'Self_Employed']='No'\n",
    "data=data.drop(index=data.loc[data['LoanAmount'].isnull(),:].index)\n",
    "data.loc[data['Loan_Amount_Term'].isnull(),'Loan_Amount_Term']=0\n",
    "data.loc[data['Credit_History'].isnull(),'Credit_History']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Credit_History']=data['Credit_History'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "encoding_minmax=defaultdict(MinMaxScaler)\n",
    "features_num=['ApplicantIncome']\n",
    "for feat in features_num:\n",
    "    encoded_df=pd.DataFrame()\n",
    "    #d=pd.DataFrame(encoding_minmax(feat).fit_transform(new_df[feat]))\n",
    "    d=pd.DataFrame(encoding_minmax[feat].fit_transform(data[[feat]]))\n",
    "    test_column=d.columns.values\n",
    "    list_column=[feat+'_'+'minmax' for j in test_column]\n",
    "    d.columns=list_column\n",
    "    encoded_df=pd.concat([encoded_df,d],axis=1).reset_index(drop=True)\n",
    "    data.drop(feat,axis=1,inplace=True)\n",
    "    data=data.reset_index(drop=True)\n",
    "    data=pd.concat([data,encoded_df],axis=1)\n",
    "import pickle\n",
    "with open('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\2019\\\\Deployment\\\\Deploy_Flask\\\\Deploy_Flask\\\\LoanPrediction\\\\minmax_pickle.pkl','wb') as f:\n",
    "    pickle.dump(encoding_minmax,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "encoding_standardscaler=defaultdict(StandardScaler)\n",
    "features_num=['LoanAmount']\n",
    "for feat in features_num:\n",
    "    encoded_df=pd.DataFrame()\n",
    "    #d=pd.DataFrame(encoding_minmax(feat).fit_transform(new_df[feat]))\n",
    "    d=pd.DataFrame(encoding_standardscaler[feat].fit_transform(data[[feat]]))\n",
    "    test_column=d.columns.values\n",
    "    list_column=[feat+'_'+'minmax' for j in test_column]\n",
    "    d.columns=list_column\n",
    "    encoded_df=pd.concat([encoded_df,d],axis=1).reset_index(drop=True)\n",
    "    data.drop(feat,axis=1,inplace=True)\n",
    "    data=data.reset_index(drop=True)\n",
    "    data=pd.concat([data,encoded_df],axis=1)\n",
    "with open('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\2019\\\\Deployment\\\\Deploy_Flask\\\\Deploy_Flask\\\\LoanPrediction\\\\standardscaler_pickle.pkl','wb') as f:\n",
    "    pickle.dump(encoding_standardscaler,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "encoding_binarizer=defaultdict(LabelBinarizer)\n",
    "col_nominal=['Married','Gender']\n",
    "for feat in col_nominal:\n",
    "    encoded_df=pd.DataFrame()\n",
    "    d=pd.DataFrame(encoding_binarizer[feat].fit_transform(data[feat]))\n",
    "    test_column=d.columns.values\n",
    "    list_columns=[feat+'_'+str(j) for j in test_column]\n",
    "    #print(list_columns)\n",
    "    d.columns=list_columns\n",
    "    #print(d.head())\n",
    "    encoded_df=pd.concat([encoded_df,d],axis=1).reset_index(drop=True)\n",
    "    data.drop(feat,axis=1,inplace=True)\n",
    "    data=data.reset_index(drop=True)\n",
    "    data=pd.concat([data,encoded_df],axis=1)\n",
    "with open('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\2019\\\\Deployment\\\\Deploy_Flask\\\\Deploy_Flask\\\\LoanPrediction\\\\binarizer_pickle.pkl','wb') as f:\n",
    "    pickle.dump(encoding_binarizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "encoding_labelencoder=defaultdict(LabelEncoder)\n",
    "col_ordinal=['Education','Property_Area','Loan_Status','Dependents','Credit_History']\n",
    "for feat in col_ordinal:\n",
    "    encoded_df=pd.DataFrame()\n",
    "    d=pd.DataFrame(encoding_labelencoder[feat].fit_transform(data[feat]))\n",
    "    test_column=d.columns.values\n",
    "    list_columns=[feat+'_'+str(j) for j in test_column]\n",
    "    d.columns=list_columns\n",
    "    encoded_df=pd.concat([encoded_df,d],axis=1).reset_index(drop=True)\n",
    "    data.drop(feat,axis=1,inplace=True)\n",
    "    data=data.reset_index(drop=True)\n",
    "    data=pd.concat([data,encoded_df],axis=1)\n",
    "with open('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\2019\\\\Deployment\\\\Deploy_Flask\\\\Deploy_Flask\\\\LoanPrediction\\\\labelencoder_pickle.pkl','wb') as f:\n",
    "    pickle.dump(encoding_labelencoder,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Loan_ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(data.drop('Loan_Status_0',axis=1),data['Loan_Status_0'],test_size=0.30,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "#with open('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\2019\\\\Deployment\\\\Deploy_Flask\\\\Deploy_Flask\\\\LoanPrediction\\\\LogisticRegression_MODEL.pkl','wb') as f:\n",
    "pickle_out = open(\"C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\2019\\\\Deployment\\\\Deploy_Flask\\\\Deploy_Flask\\\\LoanPrediction\\\\LogisticRegression_MODEL.pkl\",\"wb\")\n",
    "pickle.dump(classifier, pickle_out)\n",
    "saved_pickle_file.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
